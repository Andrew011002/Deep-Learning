{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tonimo/Documents/Developing/Repos/Deep-Learning/deep-learning-venv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from transformer import Transformer\n",
    "from metrics import Evaluator\n",
    "from datasets import load_dataset\n",
    "from utils import *\n",
    "from train import *\n",
    "from inference import *\n",
    "from tokenizer import *\n",
    "from config import *\n",
    "\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset opus100 (/Users/tonimo/.cache/huggingface/datasets/opus100/de-en/0.0.0/256f3196b69901fb0c79810ef468e2c4ed84fbd563719920b1ff1fdc750f7704)\n",
      "Found cached dataset opus100 (/Users/tonimo/.cache/huggingface/datasets/opus100/de-en/0.0.0/256f3196b69901fb0c79810ef468e2c4ed84fbd563719920b1ff1fdc750f7704)\n"
     ]
    }
   ],
   "source": [
    "traindict = load_dataset(\"opus100\", \"de-en\", split=\"train\")\n",
    "testdict = load_dataset(\"opus100\", \"de-en\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, train_labels = get_split(traindict, \"en\", \"de\", size=train_size)\n",
    "test_inputs, test_labels = get_split(testdict, \"en\", \"de\", size=test_size)\n",
    "trainset = Dataset(train_inputs, train_labels)\n",
    "testset = Dataset(test_inputs, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It was tough enough finding out he was dead, w...</td>\n",
       "      <td>Die vier Länder werden im kommenden Dezember i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>And I, the old fool, sucked it in, I believed ...</td>\n",
       "      <td>Du begreifst sehr schnell.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In 1357 the castle was owned by Franz von Rave...</td>\n",
       "      <td>Frau Präsidentin! Der Rückbau veralteter kernt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who is correct?</td>\n",
       "      <td>Zur Förderung gemeinsamer Aufsichtskonzepte en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All I see when I look in your ridiculous face ...</td>\n",
       "      <td>Wir sind ein Pflegeheim, wo wir kümmern uns um...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              inputs  \\\n",
       "0  It was tough enough finding out he was dead, w...   \n",
       "1  And I, the old fool, sucked it in, I believed ...   \n",
       "2  In 1357 the castle was owned by Franz von Rave...   \n",
       "3                                    Who is correct?   \n",
       "4  All I see when I look in your ridiculous face ...   \n",
       "\n",
       "                                              labels  \n",
       "0  Die vier Länder werden im kommenden Dezember i...  \n",
       "1                         Du begreifst sehr schnell.  \n",
       "2  Frau Präsidentin! Der Rückbau veralteter kernt...  \n",
       "3  Zur Förderung gemeinsamer Aufsichtskonzepte en...  \n",
       "4  Wir sind ein Pflegeheim, wo wir kümmern uns um...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainframe = trainset.dataframe()\n",
    "trainframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Posted: 26 Mar 2010, 17:58</td>\n",
       "      <td>Ein gutes Zeichen. Vielleicht muss ich nichts ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>==Communities=====Cities===* Alabaster* Birmin...</td>\n",
       "      <td># Antwort: 11 - 14.08.2012 um 11:36 Uhr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's a little dull.</td>\n",
       "      <td>Hat jemand von Ihnen in der Nachbarschaft hell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Garments of the type described in subheading 6...</td>\n",
       "      <td>Nun, nicht gerade bestens.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For the mystic, everything is connected: there...</td>\n",
       "      <td>Es wäre schade, wenn China, der neue industrie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              inputs  \\\n",
       "0                         Posted: 26 Mar 2010, 17:58   \n",
       "1  ==Communities=====Cities===* Alabaster* Birmin...   \n",
       "2                                It's a little dull.   \n",
       "3  Garments of the type described in subheading 6...   \n",
       "4  For the mystic, everything is connected: there...   \n",
       "\n",
       "                                              labels  \n",
       "0  Ein gutes Zeichen. Vielleicht muss ich nichts ...  \n",
       "1            # Antwort: 11 - 14.08.2012 um 11:36 Uhr  \n",
       "2  Hat jemand von Ihnen in der Nachbarschaft hell...  \n",
       "3                         Nun, nicht gerade bestens.  \n",
       "4  Es wäre schade, wenn China, der neue industrie...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testframe = testset.dataframe()\n",
    "testframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>It was tough enough finding out he was dead, w...</td>\n",
       "      <td>Die vier Länder werden im kommenden Dezember i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   inputs  \\\n",
       "count                                              100000   \n",
       "unique                                             100000   \n",
       "top     It was tough enough finding out he was dead, w...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                                   labels  \n",
       "count                                              100000  \n",
       "unique                                             100000  \n",
       "top     Die vier Länder werden im kommenden Dezember i...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(trainframe.isnull().values.any())\n",
    "trainframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Posted: 26 Mar 2010, 17:58</td>\n",
       "      <td>Ein gutes Zeichen. Vielleicht muss ich nichts ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            inputs  \\\n",
       "count                         1000   \n",
       "unique                        1000   \n",
       "top     Posted: 26 Mar 2010, 17:58   \n",
       "freq                             1   \n",
       "\n",
       "                                                   labels  \n",
       "count                                                1000  \n",
       "unique                                               1000  \n",
       "top     Ein gutes Zeichen. Vielleicht muss ich nichts ...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(testframe.isnull().values.any())\n",
    "testframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('22 Then Joab, falling down on his face on the earth, gave the king honour and blessing; and Joab said, Today it is clear to your servant that I have grace in your eyes, my lord king, because the king has given effect to the request of his servant.',\n",
       "  'https://www.hoteldiagonalzero.com/wp-content/blogs.dir/406/files/rooms_triple/triple001.jpg')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A week ago, she was basically Amish.',\n",
       "  'Die nach Abschnitt 11.2.1. ermittelten Maße jeder Tafel der Probe dürfen nicht unter dem bestellten Nennmaß liegen.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer saved\n"
     ]
    }
   ],
   "source": [
    "corpus_en = trainset.corpus(data=\"inputs\") + testset.corpus(data=\"inputs\")\n",
    "corpus_de = trainset.corpus(data=\"labels\") + testset.corpus(data=\"labels\")\n",
    "tokenizer_en = Nerdimizer()\n",
    "tokenizer_de = Nerdimizer()\n",
    "tokenizer_en.train(corpus_en, size=vocab_size_english)\n",
    "tokenizer_de.train(corpus_de, size=vocab_size_german)\n",
    "translator = Translator(tokenizer_en, tokenizer_de)\n",
    "save_tokenizer(translator, \"translator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input tokens: 32000\n",
      "Number of output tokens: 32000\n"
     ]
    }
   ],
   "source": [
    "en_vocab, de_vocab = translator.vocab_size()\n",
    "start, end, pad = translator[\"[S]\"], translator[\"[E]\"], translator[\"[P]\"]\n",
    "print(f\"Number of input tokens: {en_vocab}\\nNumber of output tokens: {de_vocab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maxlen: 256\n"
     ]
    }
   ],
   "source": [
    "translator.padon(maxlen, end=True, pad_id=pad)\n",
    "translator.truncon(maxlen, end=True)\n",
    "tokenized_trainset = trainset.tokenized(translator, model=True)\n",
    "dataloader = tokenized_trainset.dataloader(batch_size=batch_size, drop_last=False)\n",
    "print(f\"Maxlen: {maxlen}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Trainable Paramaters: 76.9M\n",
      "Size of Model: 294.3MB\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(en_vocab, de_vocab, maxlen, pad_id=pad, dm=dm, nhead=nhead, layers=layers, dff=dff,\n",
    "                    bias=bias, dropout=dropout, eps=eps)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=betas, eps=adam_eps)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=factor, patience=patience)\n",
    "search = Beam(model, start, end, maxlen, beam_width=beam_width, breadth=max_breadth, \n",
    "                mode=search_mode, alpha=alpha)\n",
    "evaluator = Evaluator(testset, translator, search, \"[S]\", \"[E]\", maxlen, sample=sample_size, ngrams=ngrams, \n",
    "                    bleu_goal=bleu_goal, mode=\"geometric\", device=device)\n",
    "clock = Clock()\n",
    "checkpoint = Checkpoint(dataloader, model, optimizer, scheduler, evaluator, clock, epochs=save_every, \n",
    "                    path=\"checkpoint\", overwrite=overwrite)\n",
    "model.to(device)\n",
    "print(f\"Number of Trainable Paramaters: {parameter_count(model):.1f}M\\nSize of Model: {model_size(model):.1f}MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Started\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(dataloader, model, optimizer, scheduler, evaluator, checkpoint, clock,\n\u001b[1;32m      2\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs, warmups\u001b[39m=\u001b[39;49mwarmups, verbose\u001b[39m=\u001b[39;49mverbose, device\u001b[39m=\u001b[39;49mdevice)\n",
      "File \u001b[0;32m~/Documents/Developing/Repos/Deep-Learning/Transformer/train.py:38\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, optimizer, scheduler, evaluator, checkpoint, clock, epochs, warmups, verbose, device)\u001b[0m\n\u001b[1;32m     36\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     37\u001b[0m \u001b[39m# get pred & reshape outputs\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m pred \u001b[39m=\u001b[39m model(src, tgt, src_mask\u001b[39m=\u001b[39;49msrc_mask, tgt_mask\u001b[39m=\u001b[39;49mtgt_mask) \u001b[39m# shape: pred - (batch_size, seq_len, vocab_size)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m pred, out \u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, pred\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)), out\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m# shape: pred - (batch_size * seq_len, vocab_size) out - (batch_size * seq_len)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39m# calc loss & backprop\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Developing/Repos/Deep-Learning/deep-learning-venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Developing/Repos/Deep-Learning/Transformer/transformer.py:29\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask)\u001b[0m\n\u001b[1;32m     26\u001b[0m d_out, attn, attn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(e_out, tgt, src_mask\u001b[39m=\u001b[39msrc_mask, tgt_mask\u001b[39m=\u001b[39mtgt_mask)\n\u001b[1;32m     28\u001b[0m \u001b[39m# linear project out of decoder: out (batch_size, tgt_len, vocab_size)\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmatmul(d_out, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinear\u001b[39m.\u001b[39;49mT)\n\u001b[1;32m     30\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train(dataloader, model, optimizer, scheduler, evaluator, checkpoint, clock,\n",
    "    # epochs=epochs, warmups=warmups, verbose=verbose, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cdd6e1c2b78b644f0d9d9d71785509219b94538d762b98250c0a1db53509cbf1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
