{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tonimo/Documents/Developing/Repos/Deep-Learning/deep-learning-venv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from transformer import Transformer\n",
    "from metrics import Evaluator\n",
    "from datasets import load_dataset\n",
    "from utils import *\n",
    "from train import *\n",
    "from inference import *\n",
    "from tokenizer import *\n",
    "from config import *\n",
    "\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset opus100 (/Users/tonimo/.cache/huggingface/datasets/opus100/de-en/0.0.0/256f3196b69901fb0c79810ef468e2c4ed84fbd563719920b1ff1fdc750f7704)\n",
      "Found cached dataset opus100 (/Users/tonimo/.cache/huggingface/datasets/opus100/de-en/0.0.0/256f3196b69901fb0c79810ef468e2c4ed84fbd563719920b1ff1fdc750f7704)\n"
     ]
    }
   ],
   "source": [
    "traindict = load_dataset(\"opus100\", \"de-en\", split=\"train\")\n",
    "testdict = load_dataset(\"opus100\", \"de-en\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, train_labels = get_split(traindict, \"en\", \"de\", size=1000)\n",
    "test_inputs, test_labels = get_split(testdict, \"en\", \"de\", size=100)\n",
    "trainset = Dataset(train_inputs, train_labels)\n",
    "testset = Dataset(test_inputs, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In that case Article 2 applies.</td>\n",
       "      <td>Marktanteil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Push! Push!</td>\n",
       "      <td>Komm rein.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>APPROVAL GRANTED</td>\n",
       "      <td>05:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Having regard to the proposal from the Commiss...</td>\n",
       "      <td>Artikel 58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-Come on.</td>\n",
       "      <td>Wenn du einen Gegner hast, musst du dir eines ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              inputs  \\\n",
       "0                    In that case Article 2 applies.   \n",
       "1                                        Push! Push!   \n",
       "2                                   APPROVAL GRANTED   \n",
       "3  Having regard to the proposal from the Commiss...   \n",
       "4                                          -Come on.   \n",
       "\n",
       "                                              labels  \n",
       "0                                        Marktanteil  \n",
       "1                                         Komm rein.  \n",
       "2                                              05:35  \n",
       "3                                         Artikel 58  \n",
       "4  Wenn du einen Gegner hast, musst du dir eines ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainframe = trainset.dataframe()\n",
    "trainframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I mean, most people, they see another person w...</td>\n",
       "      <td>- Nein. Ich bin niemandes Mäuschen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>if ever someone's bones are found 20 feet out ...</td>\n",
       "      <td>This new page was generated in 0.010168 seconds.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Osteoarthritis, rheumatoid arthritis and chron...</td>\n",
       "      <td>Man kann nicht immer gewinnen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>That motherfucker who did talk had a strange a...</td>\n",
       "      <td>1Co 15:43 gesät wird in Unehre und auferweckt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I just wish that you would give me more than e...</td>\n",
       "      <td>Echogerät ist bei mir eine Dolby-Revox mit reg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              inputs  \\\n",
       "0  I mean, most people, they see another person w...   \n",
       "1  if ever someone's bones are found 20 feet out ...   \n",
       "2  Osteoarthritis, rheumatoid arthritis and chron...   \n",
       "3  That motherfucker who did talk had a strange a...   \n",
       "4  I just wish that you would give me more than e...   \n",
       "\n",
       "                                              labels  \n",
       "0                - Nein. Ich bin niemandes Mäuschen.  \n",
       "1   This new page was generated in 0.010168 seconds.  \n",
       "2                     Man kann nicht immer gewinnen.  \n",
       "3  1Co 15:43 gesät wird in Unehre und auferweckt ...  \n",
       "4  Echogerät ist bei mir eine Dolby-Revox mit reg...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testframe = testset.dataframe()\n",
    "testframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>In that case Article 2 applies.</td>\n",
       "      <td>Marktanteil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 inputs       labels\n",
       "count                              1000         1000\n",
       "unique                             1000         1000\n",
       "top     In that case Article 2 applies.  Marktanteil\n",
       "freq                                  1            1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(trainframe.isnull().values.any())\n",
    "trainframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>I mean, most people, they see another person w...</td>\n",
       "      <td>- Nein. Ich bin niemandes Mäuschen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   inputs  \\\n",
       "count                                                 100   \n",
       "unique                                                100   \n",
       "top     I mean, most people, they see another person w...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                     labels  \n",
       "count                                   100  \n",
       "unique                                  100  \n",
       "top     - Nein. Ich bin niemandes Mäuschen.  \n",
       "freq                                      1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(testframe.isnull().values.any())\n",
    "testframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Exactly what you said!', 'Du kennst sie.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Best practice consulting for software globalization - we help you make sure that your applications and products support the cultural, legal and technical requirements of regional markets',\n",
       "  'Sollten jemals Knochen 6 m von meinem Schlafzimmer gefunden werden, mache ich mir echt Sorgen.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer saved\n"
     ]
    }
   ],
   "source": [
    "corpus_en = trainset.corpus(data=\"inputs\") + testset.corpus(data=\"inputs\")\n",
    "corpus_de = trainset.corpus(data=\"labels\") + testset.corpus(data=\"labels\")\n",
    "tokenizer_en = Nerdimizer()\n",
    "tokenizer_de = Nerdimizer()\n",
    "tokenizer_en.train(corpus_en, size=vocab_size_english)\n",
    "tokenizer_de.train(corpus_de, size=vocab_size_german)\n",
    "translator = Translator(tokenizer_en, tokenizer_de)\n",
    "save_tokenizer(translator, \"translator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input tokens: 4498\n",
      "Number of output tokens: 5659\n"
     ]
    }
   ],
   "source": [
    "en_vocab, de_vocab = translator.vocab_size()\n",
    "start, end, pad = translator[\"[S]\"], translator[\"[E]\"], translator[\"[P]\"]\n",
    "print(f\"Number of input tokens: {en_vocab}\\nNumber of output tokens: {de_vocab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maxlen: 10\n"
     ]
    }
   ],
   "source": [
    "translator.padon(maxlen, end=True, pad_id=pad)\n",
    "translator.truncon(maxlen, end=True)\n",
    "tokenized_trainset = trainset.tokenized(translator, model=True)\n",
    "dataloader = tokenized_trainset.dataloader(batch_size=16, drop_last=False)\n",
    "print(f\"Maxlen: {maxlen}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Trainable Paramaters: 6.3M\n",
      "Size of Model: 24.0MB\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(en_vocab, de_vocab, maxlen, pad_id=pad, dm=256, nhead=nhead, layers=2, dff=1024,\n",
    "                    bias=bias, dropout=dropout, eps=eps)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=betas, eps=adam_eps)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=factor, patience=patience)\n",
    "search = Beam(model, start, end, maxlen, beam_width=beam_width, breadth=max_breadth, \n",
    "                mode=search_mode, alpha=alpha, device=device)\n",
    "evaluator = Evaluator(testset, translator, search, sample=sample_size, \n",
    "                        ngrams=ngrams, goal_bleu=goal_bleu, mode=\"geometric\")\n",
    "clock = Clock()\n",
    "checkpoint = Checkpoint(dataloader, model, optimizer, scheduler, evaluator, clock, \n",
    "                        epochs=save_every, path=\"checkpoint\", overwrite=overwrite)\n",
    "model.to(device)\n",
    "print(f\"Number of Trainable Paramaters: {parameter_count(model):.1f}M\\nSize of Model: {model_size(model):.1f}MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Started\n",
      "-------------------------------------------------------------------------------\n",
      "Epoch 1 Complete | Epoch Duration: 00:00:09 | Elapsed Training Time: 00:00:09 |\n",
      "Metrics | Epoch Loss: 8.3027 | BLEU Score: 0.0 | \n",
      "Other Info | Scheduler Warmup Step: True | Checkpoint Saved: False |\n",
      "-------------------------------------------------------------------------------\n",
      "Epoch 2 Complete | Epoch Duration: 00:00:07 | Elapsed Training Time: 00:00:15 |\n",
      "Metrics | Epoch Loss: 7.8187 | BLEU Score: 0.0 | \n",
      "Other Info | Scheduler Warmup Step: True | Checkpoint Saved: False |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(dataloader, model, optimizer, scheduler, evaluator, checkpoint, clock,\n\u001b[1;32m      2\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs, warmups\u001b[39m=\u001b[39;49mwarmups, verbose\u001b[39m=\u001b[39;49mverbose, device\u001b[39m=\u001b[39;49mdevice)\n",
      "File \u001b[0;32m~/Documents/Developing/Repos/Deep-Learning/Transformer/train.py:39\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, optimizer, scheduler, evaluator, checkpoint, clock, epochs, warmups, verbose, device)\u001b[0m\n\u001b[1;32m     37\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     38\u001b[0m \u001b[39m# get pred & reshape outputs\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m pred \u001b[39m=\u001b[39m model(src, tgt, src_mask\u001b[39m=\u001b[39;49msrc_mask, tgt_mask\u001b[39m=\u001b[39;49mtgt_mask) \u001b[39m# shape: pred - (batch_size, seq_len, vocab_size)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m pred, out \u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, pred\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)), out\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m# shape: pred - (batch_size * seq_len, vocab_size) out - (batch_size * seq_len)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39m# calc loss & backprop\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Developing/Repos/Deep-Learning/deep-learning-venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Developing/Repos/Deep-Learning/Transformer/transformer.py:26\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask)\u001b[0m\n\u001b[1;32m     23\u001b[0m e_out, attn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(src, src_mask\u001b[39m=\u001b[39msrc_mask)\n\u001b[1;32m     25\u001b[0m \u001b[39m# decode embeddings shape: d_out - (batch_size, tgt_len, dm)\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m d_out, attn, attn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(e_out, tgt, src_mask\u001b[39m=\u001b[39;49msrc_mask, tgt_mask\u001b[39m=\u001b[39;49mtgt_mask)\n\u001b[1;32m     28\u001b[0m \u001b[39m# linear project out of decoder: out (batch_size, tgt_len, vocab_size)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmatmul(d_out, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear\u001b[39m.\u001b[39mT)\n",
      "File \u001b[0;32m~/Documents/Developing/Repos/Deep-Learning/deep-learning-venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Developing/Repos/Deep-Learning/Transformer/layers.py:98\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39m# pass src & tgt through stack of decoders (out of layer is in for next)\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[39mfor\u001b[39;00m decoder \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstack:\n\u001b[0;32m---> 98\u001b[0m     x, attn1, attn2 \u001b[39m=\u001b[39m decoder(src, x, src_mask\u001b[39m=\u001b[39;49msrc_mask, tgt_mask\u001b[39m=\u001b[39;49mtgt_mask)\n\u001b[1;32m     99\u001b[0m out \u001b[39m=\u001b[39m x\n\u001b[1;32m    100\u001b[0m \u001b[39mreturn\u001b[39;00m out, attn1, attn2\n",
      "File \u001b[0;32m~/Documents/Developing/Repos/Deep-Learning/deep-learning-venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Developing/Repos/Deep-Learning/Transformer/layers.py:68\u001b[0m, in \u001b[0;36mDecoderLayer.forward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask)\u001b[0m\n\u001b[1;32m     66\u001b[0m x \u001b[39m=\u001b[39m tgt\n\u001b[1;32m     67\u001b[0m x_out, attn1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaskmultihead(x, x, x, mask\u001b[39m=\u001b[39mtgt_mask)\n\u001b[0;32m---> 68\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm1(x \u001b[39m+\u001b[39;49m x_out)\n\u001b[1;32m     70\u001b[0m \u001b[39m# calc context, add & norm (residual connections) shape: x - (batch_size, tgt_len, dm)\u001b[39;00m\n\u001b[1;32m     71\u001b[0m x_out, attn2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmultihead(x, src, src, mask\u001b[39m=\u001b[39msrc_mask)\n",
      "File \u001b[0;32m~/Documents/Developing/Repos/Deep-Learning/deep-learning-venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Developing/Repos/Deep-Learning/Transformer/sublayers.py:87\u001b[0m, in \u001b[0;36mNorm.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39m# normalize, scale, & shift\u001b[39;00m\n\u001b[1;32m     86\u001b[0m norm \u001b[39m=\u001b[39m (x \u001b[39m-\u001b[39m mean) \u001b[39m/\u001b[39m std\n\u001b[0;32m---> 87\u001b[0m \u001b[39mreturn\u001b[39;00m norm \u001b[39m*\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgamma \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbeta\n",
      "File \u001b[0;32m~/Documents/Developing/Repos/Deep-Learning/deep-learning-venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1252\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1249\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_is_full_backward_hook\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[1;32m   1250\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_full_backward_hook \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1252\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[Tensor, \u001b[39m'\u001b[39m\u001b[39mModule\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m   1253\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_parameters\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[1;32m   1254\u001b[0m         _parameters \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m[\u001b[39m'\u001b[39m\u001b[39m_parameters\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(dataloader, model, optimizer, scheduler, evaluator, checkpoint, clock,\n",
    "    epochs=5, warmups=warmups, verbose=verbose, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cdd6e1c2b78b644f0d9d9d71785509219b94538d762b98250c0a1db53509cbf1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
