{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from utils import Dataset, load_model, save_model\n",
    "from training import train, predict, prompt\n",
    "from datasets import load_dataset\n",
    "from tokenizer import Nerdimizer, save_tokenizer, load_tokenizer\n",
    "from transformer import Transformer\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration en2de-176cd02372067e72\n",
      "Found cached dataset europa_eac_tm (/Users/tonimo/.cache/huggingface/datasets/europa_eac_tm/en2de-176cd02372067e72/0.0.0/955b2501a836c2ea49cfe3e719aec65dcbbc3356bbbe53cf46f08406eb77386a)\n"
     ]
    }
   ],
   "source": [
    "datadict = load_dataset(\"europa_eac_tm\", language_pair=(\"en\", \"de\"), split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [pair[\"en\"] for pair in datadict[\"translation\"]]\n",
    "labels = [pair[\"de\"] for pair in datadict[\"translation\"]]\n",
    "dataset = Dataset(inputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nr. teachers/trainers</td>\n",
       "      <td>Anzahl Lehrer(innen)/Trainer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>APPLICANT</td>\n",
       "      <td>ANTRAGSTELLERIN/ANTRAGSTELLER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The grant application will be processed by com...</td>\n",
       "      <td>Der Förderantrag wird elektronisch verarbeitet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To be signed by the person legally authorised ...</td>\n",
       "      <td>Unterschrift der Person, die rechtsverbindlich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DATE OF BIRTH</td>\n",
       "      <td>GEBURTSDATUM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              inputs  \\\n",
       "0                              Nr. teachers/trainers   \n",
       "1                                          APPLICANT   \n",
       "2  The grant application will be processed by com...   \n",
       "3  To be signed by the person legally authorised ...   \n",
       "4                                      DATE OF BIRTH   \n",
       "\n",
       "                                              labels  \n",
       "0                       Anzahl Lehrer(innen)/Trainer  \n",
       "1                      ANTRAGSTELLERIN/ANTRAGSTELLER  \n",
       "2  Der Förderantrag wird elektronisch verarbeitet...  \n",
       "3  Unterschrift der Person, die rechtsverbindlich...  \n",
       "4                                       GEBURTSDATUM  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset.dataframe()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4473</td>\n",
       "      <td>4473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4452</td>\n",
       "      <td>4312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Event</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       inputs labels\n",
       "count    4473   4473\n",
       "unique   4452   4312\n",
       "top     Event      x\n",
       "freq        2     29"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.isnull().values.any())\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Other financial activities'],\n",
       " ['Mit Finanz-  und Versicherungsdienstleistungen verbundene Tätigkeiten'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of word piece tokens: 15693\n"
     ]
    }
   ],
   "source": [
    "corpus = dataset.corpus()\n",
    "tokenizer = Nerdimizer()\n",
    "tokenizer.train(corpus)\n",
    "vocab_size = len(tokenizer)\n",
    "maxlen = dataset.avg_tokenized_len(tokenizer, factor=3)\n",
    "start, end, pad = tokenizer[\"[S]\"], tokenizer[\"[E]\"], tokenizer[\"[P]\"]\n",
    "tokenizer.padon(maxlen, pad_id=pad)\n",
    "tokenizer.truncon(maxlen)\n",
    "print(f\"Number of word piece tokens: {len(tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['[S]', 'arts', '(', 'others', ')', '[E]', '[P]', '[P]', '[P]', '[P]', '[P]', '[P]', '[P]', '[P]', '[P]', '[P]', '[P]', '[P]', '[P]', '[P]', '[P]', '[P]']]\n",
      "[['[S]', 'kunst', '(', 'andere', ')', '[E]', '[P]', '[P]', '[P]', '[P]', '[P]', '[P]', '[P]', '[P]', '[P]', '[P]', '[P]', '[P]', '[P]', '[P]', '[P]', '[P]']]\n"
     ]
    }
   ],
   "source": [
    "sample = dataset.sample()\n",
    "print(tokenizer(sample[0]))\n",
    "print(tokenizer(sample[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,   673,  1560,    11,   778,  2317,  4529,     1,     3,     3,\n",
       "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3],\n",
       "        [    0,  1628,    18,   862,     1,     3,     3,     3,     3,     3,\n",
       "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3],\n",
       "        [    0,   179,  3835,   685,  3411,  6536,    17,  1213,  9398,  1554,\n",
       "            11,   517,  3888,    15, 15259,    15,  7049,   779,   826,   479,\n",
       "          3146,     1],\n",
       "        [    0,  2155,   179,   381,    15,   185,  7148,   278,   185,  4153,\n",
       "           623, 12341,  3379,    17,     1,     3,     3,     3,     3,     3,\n",
       "             3,     3],\n",
       "        [    0, 14810,     1,     3,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3],\n",
       "        [    0,    21,    12,  9417,   181,  5336,   278,   473, 14892,     1,\n",
       "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3],\n",
       "        [    0,  1732,     1,     3,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3],\n",
       "        [    0,  1239,   278,  4532,  1840,  8408,    29,   483,  4296,   222,\n",
       "         14182,   352, 15502,   222,    18,    54,  8799,  1309,   157,   179,\n",
       "          1231,     1],\n",
       "        [    0,  1348,  4196,     1,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3],\n",
       "        [    0,  8822,  1041,     1,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3],\n",
       "        [    0,    16,  4008,   197,  3618,    15,   650,   389,   469,  2153,\n",
       "          1795,  1591,   181,   490,  7220,   651,  5388,  1591, 12325,    17,\n",
       "             1,     3],\n",
       "        [    0,  1330,  9269,  2035,    15, 11245,   157,   444,    15,  6275,\n",
       "           352,   334,    17,     1,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3],\n",
       "        [    0,  4564,    16,  3399,    11,  4760,   181,  4330,  9821,    12,\n",
       "             1,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3],\n",
       "        [    0,   643,   197,    15,   517,   185,  1376,   632,   185,  4768,\n",
       "           181,   185,  2709,  4506,   990,    17,     1,     3,     3,     3,\n",
       "             3,     3],\n",
       "        [    0,  3821,     1,     3,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3],\n",
       "        [    0,   521,    11,  1781,    12,     1,     3,     3,     3,     3,\n",
       "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3],\n",
       "        [    0,   262,   518,   197,  1834,  5268,   202,    15,   185,   197,\n",
       "           202,   185,   849,   352,   185,   886,  2690,  6074,  2841,    15,\n",
       "           607,     1],\n",
       "        [    0,    20,    12,  5045,   278,   185,  1784,   295,  5216,   181,\n",
       "            18,   352,  4686,     1,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3],\n",
       "        [    0,   517,   676,   197,   249,   179,   825,  6531,    33,     1,\n",
       "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3],\n",
       "        [    0,     8,     1,     3,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3],\n",
       "        [    0,   185,  8426,  1278,  3879,   157,   877,   179,  1900,  2295,\n",
       "            15,   185,   774,   297,   278,  1333,   870,  1066,    17,     1,\n",
       "             3,     3],\n",
       "        [    0,   262,   643,   197,   185,  2384,    16,   181,  9381,  1784,\n",
       "          1411,  4683,   295,    11,    20,    12,   185,  5216,   181,    18,\n",
       "           352,     1],\n",
       "        [    0,    37,    17,    20,    17,  3793,   710,     1,     3,     3,\n",
       "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3],\n",
       "        [    0,   673,   850,    18,  1560,   373,  1451,  1848,     1,     3,\n",
       "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3],\n",
       "        [    0, 15597,     1,     3,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3],\n",
       "        [    0,   744,  2373,    15,   650,   185,   157,  1155,   337,  2877,\n",
       "          1136,    11,  1883,  6649,    12,  5133,  6917,  2305,   662,    15,\n",
       "           181,     1],\n",
       "        [    0,    16,   661,   490,   157,  8386,  6998,    15,   490, 12924,\n",
       "         14867,   685,   181,   650,   473, 15456,   490, 12921, 14209,   479,\n",
       "            30,     1],\n",
       "        [    0,  1958,  1966,  4334,    17,  7991,    17,   745,    18,    56,\n",
       "            18,  9432,    18,  7273,  7434,    48,    31,    41,     9,    49,\n",
       "          7448,     1],\n",
       "        [    0,  3920,   278,   185,  1359,   222,  1079,   181,  1843,   222,\n",
       "          4227,   599,  1850,   249,  2395,     1,     3,     3,     3,     3,\n",
       "             3,     3],\n",
       "        [    0,  3013,  8413,     1,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3],\n",
       "        [    0,   185,  4601, 12395,  8977,   490,   373,   315,  4601, 13306,\n",
       "          3839,    17,     1,     3,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3],\n",
       "        [    0, 12236,     1,     3,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.tokenized(tokenizer)\n",
    "dataloader = tokenized_dataset.dataloader(batch_size=32, drop_last=False)\n",
    "next(iter(dataloader))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(vocab_size=len(tokenizer), maxlen=maxlen, pad_id=pad, \n",
    "                    dm=512, nhead=8, layers=6, dff=2048)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5, betas=(0.9, 0.98), eps=10e-9)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.9, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, optimizer, scheduler, dataloader, epochs=1000, warmups=100, verbose=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, \"Transformer-Base\", \"models/\")\n",
    "save_tokenizer(tokenizer, \"Tokenizer-en-de\", \"models/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cdd6e1c2b78b644f0d9d9d71785509219b94538d762b98250c0a1db53509cbf1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
