{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tonimo/Documents/Developing/Repos/Deep-Learning/deep-learning-env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformer import Transformer\n",
    "from utils import create_dataloader\n",
    "from training import train, predict, ascending_data\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5000\n",
    "vocab_size = 100\n",
    "sos = vocab_size\n",
    "eos = vocab_size + 1\n",
    "maxlen = 10\n",
    "pad_idx = 0\n",
    "inputs, outputs = ascending_data(vocab_size, n, maxlen, sos, eos, pad_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.   7. 101.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[101.   7. 100.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"
     ]
    }
   ],
   "source": [
    "i = np.random.randint(0, len(inputs))\n",
    "print(inputs[i])\n",
    "print(outputs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = create_dataloader(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(vocab_size + 2, maxlen + 2, pad_idx)\n",
    "optimizer = optim.Adam(model.parameters(), 0.00001, betas=(0.9, 0.98), eps=1e-10)\n",
    "\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Started\n",
      "Epoch 1 Started\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (12) must match the size of tensor b (10) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(model, optimizer, dataloader, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/Developing/Repos/Deep-Learning/Transformer/training.py:53\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, dataloader, epochs, device, verbose)\u001b[0m\n\u001b[1;32m     51\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     52\u001b[0m \u001b[39m# get prediction and reshape outputs\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m pred \u001b[39m=\u001b[39m model(src, tgt, src_mask\u001b[39m=\u001b[39;49msrc_mask, tgt_mask\u001b[39m=\u001b[39;49mtgt_mask) \u001b[39m# shape: (batch_size, seq_len, vocab_size)\u001b[39;00m\n\u001b[1;32m     54\u001b[0m pred, out \u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, pred\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)), out\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m# shape pred: (batch_size * seq_len, vocab_size) out: (batch_size * seq_len)\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[39m# calculate loss and backpropagate\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Developing/Repos/Deep-Learning/deep-learning-env/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Developing/Repos/Deep-Learning/Transformer/transformer.py:26\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, src, tgt, src_mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, tgt_mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     22\u001b[0m     \u001b[39m# inshape: (batch_size, seq_len)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m     \u001b[39m# embeddings + positional encodings shape: (batch_size, seq_len, dm)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(src)\n\u001b[0;32m---> 26\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpos_encoder(x)\n\u001b[1;32m     28\u001b[0m     \u001b[39m# encode embeddings shape: (batch_size, seq_len, dm)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     e_out, attn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(x, src_mask\u001b[39m=\u001b[39msrc_mask)\n",
      "File \u001b[0;32m~/Documents/Developing/Repos/Deep-Learning/deep-learning-env/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Developing/Repos/Deep-Learning/Transformer/pos_encoder.py:28\u001b[0m, in \u001b[0;36mPositionalEncoder.forward\u001b[0;34m(self, embeddings)\u001b[0m\n\u001b[1;32m     25\u001b[0m seq_len \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[39m# sum up encodings up to seq_len shape: (batch_size, seq_len, dm)\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m embeddings \u001b[39m=\u001b[39m embeddings \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpos_encodings[:, :seq_len]\n\u001b[1;32m     29\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(embeddings)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (12) must match the size of tensor b (10) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, dataloader, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15 16 17 18 19 20 21 22 23 24]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[100,  21,  20,  19,  18,  17,  16,  15,  14,  13]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "token = 15\n",
    "source = np.arange(token, token + maxlen)\n",
    "print(source)\n",
    "predict(model, source, sos, eos, maxlen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('deep-learning-env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da2a551476f66aae3613481d49d8fd33a804395c218c6f6a2807839cdafe1d12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
